### 方向

在课堂介绍的编译技术发展的基础上进行延展，更深入、具体地调研编译技术某个方向的新进展，例如：

- 深度学习编译器。
- 编译技术应用于安全领域（如ZKEVM)。
- 采用AI技术优化编译器。
- 其他类似方向。

### 说明

- 制作15分钟左右的Slides,清晰地介绍你对某个方向的调研结果，如觉必要可附调研报告（要求同前）。

- 应更深入地介绍具体的编译技术，而不是空泛而谈，不求大而全，可用20分钟内的大部分时间聚焦于能代表这个方向发展趋势的一个点进行详细介绍，力求让听者能抓住这个方向的技术特点。
- PPT的制作方面，要基于希望听者能吸收你讲的什么内容这一最终目标进行总体结构和内容的设计。文字简明、扼要，用项目符号等方式体现出逻辑，切忌大段拷贝原始素材文字。辅以图、表等更生动的形式帮助听者快速抓住你讲解的要点。字体、字号等格式要保持全篇统一。如文档撰写一样，尽量插入对象而非图片格式，只能图片格式的话，一定要清晰。老师会挑选完成得最好的1-2人在课堂报告，被选中的同学还要做一些练习，力求好的报告效果。本作业为平时普通作业和期末考试之外的额外加分，每次满分为1分，整个学期每人最多加2分。

### 想法

深度学习编译器

AI编译优化

特定领域语言

哪些通用设计，哪些编译器结构，重点IR

- 深度学习编译器的设计架构，关键组件
- 分类
- 未来的发展

### 背景

当前出现了多种多样的深度学习模型，为了简化使用，提出了多种深度学习的框架，硬件设计也越发多样化。在将计算映射到硬件的过程中，使用库函数以加速运算，但缺点在于库落后于深度学习模型的快速发展，无法充分发挥硬件潜力。

为了解决库和工具使用的缺点，并减少手动优化代码的负担，提出了一些流行的深度学习编译器。

>深度学习框架：
>
>- TensorFlow
>- Pytorch
>- MXNet
>- CNTK
>
>深度学习硬件：
>
>- 软硬件协同设计的通用硬件（CPU，GPU，增加AVX512矢量单元和张量内核）
>- 深度学习专用硬件（Google TPU）
>- 受脑科学启发的神经形态硬件
>
>库
>
>- 线性代数库：基本线性代数子程序库（BLAS）
>- 深度学习专用库：MKL-DNN，cuDNN
>
>深度学习编译器：
>
>- 输入：在深度学习框架中描述的模型定义
>- 输出：在深度学习硬件上的高效代码实现
>- 结构：类似传统编译器，分前端、中间代码表示、后端，但增加了多级IR和针对深度学习的特定优化。
>- 流行的深度学习编译器：TVM, TensorFlow Comprehensions, Glow, nGraph, XLA

### 深度学习编译器的架构

![深度学习编译器架构（图源：The Deep Learning Compiler: A Comprehensive Survey）](D:\file\大三上\编译系统原理\compilation\ot\ot1\ot1.assets\arch.gif)

[^来源]: The Deep Learning Compiler: A Comprehensive Survey

- 前端 & 高级IR：负责与硬件无关的优化

  - 前端：
    - 将深度学习模型转换为**计算图**来表示，需要支持不同框架下不同格式的转换
    - 结合通用编译器和深度学习特定优化
      - 节点级：空节点和零维张量消除
      - 块级：算子融合，算子下沉
      - 数据流级：CSE，DCE，静态内存规划，布局转换
  - 高级IR（Graph IR）
    - 表示于硬件无关的计算和控制流，设计的挑战所在：对不同的深度学习模型均有对计算和控制流的抽象能力
    - 建立控制流，建立算子和数据之间的关系
    - 为graph level优化提供接口
    - 包含编译所需的丰富语义信息
    - 扩展支持自定义算子

- 后端 & 低级IR：负责特定于硬件的优化、代码生成和翻译

  - 后端

    - 将高级IR转换为低级IR，执行特定于硬件的优化

    - 可将高级IR转换为LLVM IR，利用现有架构进行通用优化和代码生成

    - 根据模型的特点，目标硬件的特性，使用自定义的pass

      >针对特定硬件的优化
      >
      >- 硬件固有映射（harware intrinsic mapping）
      >- 内存的获取和分配
      >- 内存访问延迟隐藏
      >- 并行化
      >- 面向循环的优化

    - 使用自动调度（polyhedral model）或自动调谐（AutoTVM）的方式确定优化空间中的最优参数
    - 低级IR使用JIT或AOT进行编译，生成目标硬件对应代码

  - 低级IR

    - 针对特定硬件进行优化和代码生成

    - 根据硬件特性进行极粒度的优化

    - 允许在编译器后端使用第三方工具链

      >常见第三方工具链
      >
      >- Halide
      >
      >- polyhedral model
      >- LLVM

### 高级IR

克服传统编译器中的IR表示限制和深度学习模型的复杂计算表示，因此采用graph IR

- 高级IR的表示

  - 图IR的表示决定了图IR的表达力，也决定深度学习编译器分析的方式

  - 基于有向无环图DAG的IR

    - 节点表示算子，边表示张量
    - 分析算子之间的依赖，将传统数据依赖图的公共子表达式消除和死代码消除与之结合
    - 简单，易于编程和编译，但缺少计算范围而容易导致语义模糊

  - 基于Let-Binding的IR

    - 将变量和表达式绑定，形成新的let节点，变量更新时需要递归地先计算它作用域里的节点值

      >后续表达式就是该变量的作用域，计算变量时需要首先计算表达式的值，这样就形成了依赖关系

  - 张量计算的表示
    - Function-based：用函数封装操作符，XLA的IR采用此表达
    - Lambda expression：通过变量绑定和替换来描述计算，TVM采用
    - Einstein notation：也称为爱因斯坦求和约定，这时无需定义中间变量，IR通过未定义的变量找到真正的表达式。TensorComprehensions 采用这种形式。

- 高级IR的实现

  - 数据的表示
    - **占位符**：占位符指用一个只有形状信息的变量来代表一个 tensor，直到运算时再用数据进行填充。这样再构建计算图时就不必关心真正的数据元素，从而将计算图定义和执行分离，方便调整。
    - **未知形状表示**：这一技术常用于定义占位符，因为有些层的形状直到运行时才能知道形状，这也导致了对于边界和维数的检查需要放宽，也需要额外的机制来保证内存有效。
    - **数据布局**：数据布局描述了 tensor 如何在内存中组织，通常是从逻辑下标到内存下标的映射。值得注意的是数据布局信息可以和运算符放在一起，而非直觉上和 tensor 自己存放在一起，这样可以更好的实现特定的运算符，减少编译的开销。
    - **边界推断**：用于编译深度学习模型时决定迭代器的边界，主要是决定占位符的大小。
  - 此外 IR 设计时还需要考虑到对操作符的支持，除了算术操作符（+、-），还有神经网络操作符（卷积、池化），张量操作符（reshape、resize），广播和规约操作符（min、argmin）和控制流操作符（条件和循环），以及用户自定义的操作符

![image-20221009211016570](D:\file\大三上\编译系统原理\compilation\ot\ot1\ot1.assets\image-20221009211016570.png)

### 低级IR

- 低级IR的实现
  - **Halide-based IR**：Halide 基本思想为将计算和调度分离。相较于直接给定一个特定的模式，Halide 会尝试各种可能的调度方式并选择最好的一个。
  - **Polyhedral-based IR**：Polyhedral 模型使用 linear programming, affine transformations 以及其他的数学方法来优化具有静态控制流边界和分支的以循环为基础的代码。
  - **其他 IR**：也有其他的编译器采用了除了以上两种方式之外的 IR，然后将硬件优化交给 LLVM IR 等设施，MLIR 就是一个例子。
- 基于低级IR的代码生成



### 前端优化

- 节点级
- 块级
- 数据流级



### 后端优化

- 针对特定硬件优化
- 自动调谐
- 优化内核库